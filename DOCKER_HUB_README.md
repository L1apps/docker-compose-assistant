# Docker Compose Assistant (DCA)

**A smart, web-based editor and analyzer for Docker Compose files.**

The Docker Compose Assistant is a privacy-first web application designed to help you write, validate, and fix `docker-compose.yml` files. It runs entirely in your browser (client-side) and connects to AI providers (Google Gemini or Local LLMs) to provide intelligent suggestions, auto-formatting, and explanations.

![Version](https://img.shields.io/badge/version-1.9.1-blue) ![License](https://img.shields.io/badge/license-Apache%202.0-green)

## ğŸš€ Quick Start

The easiest way to run the assistant is using Docker Compose. You can pull from Docker Hub or GitHub Container Registry.

    services:
      dca-app:
        # Docker Hub
        image: l1apps/docker-compose-assistant:latest
        
        # GitHub Container Registry
        # image: ghcr.io/l1apps/docker-compose-assistant:latest
        
        container_name: docker-compose-assistant
        ports:
          - "8500:80" 
        restart: unless-stopped

Or run it directly with the Docker CLI:

    # Docker Hub
    docker run -d -p 8500:80 --name docker-compose-assistant l1apps/docker-compose-assistant:latest

    # GitHub Container Registry
    docker run -d -p 8500:80 --name docker-compose-assistant ghcr.io/l1apps/docker-compose-assistant:latest

Once running, access the editor at: **http://localhost:8500**

## âœ¨ Features

*   **ğŸ¤– Pluggable AI Providers**:
    *   **Google Gemini**: Use the powerful cloud-based models (requires a free API key).
    *   **Local AI (Ollama/LocalAI)**: Connect to your own local models (Llama 3, Mistral, etc.) for maximum privacy.
*   **ğŸ›¡ï¸ Privacy First**: Your code is processed client-side. If you use a local model, your data never leaves your network.
*   **âš¡ Intelligent Analysis**: Detects syntax errors, deprecated keys, and security issues.
*   **ğŸ¨ Smart Formatting**: Auto-format your YAML with standard spacing and view a "Diff" comparison before applying changes.
*   **ğŸ“ Syntax Snippets**: Instantly insert common blocks (Services, Networks, Volumes, Deploy limits, etc.) via a dropdown menu.
*   **ğŸ” Contextual Help**: Highlight any keyword in your file to get an instant explanation and example.
*   **ğŸ§­ Structure Navigation**: "Jump to Section" allows you to navigate large files easily.
*   **ğŸŒ— Themes**: Includes Light, Dark, and Dracula themes.

## âš™ï¸ Configuration

### Setting up AI
When you launch the app for the first time, a wizard will guide you. You can also configure settings later via the **Settings (âš™ï¸)** icon.

1.  **Google Gemini**: Requires an API Key from Google AI Studio.
2.  **Local AI**: Point the app to your local API endpoint (e.g., `http://localhost:11434/v1` for Ollama).

## ğŸ“¦ Image Details

*   **Port**: Exposes port `80` inside the container.
*   **Base Image**: Nginx Alpine (lightweight and fast).
*   **Architecture**: Supports AMD64 and ARM64.

## ğŸ›  Support

Developed by [Level 1 Apps (L1Apps)](https://l1apps.com).
For support or inquiries, please visit our website.

## ğŸ“„ License

Apache License 2.0